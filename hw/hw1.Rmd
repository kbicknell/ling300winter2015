---
title: 'Ling 300: Homework 1'
author: "Klinton Bicknell"
date: "Due: January 22, 2015"
output: html_document
---

This homework assignment has two parts. The first part tests your understanding of some basic concepts in probability theory and is short answer. The second part requires programming in R, and requires turning in a script you'll create, in addition to answering some short answer questions.

Probability theory
------------------

1. *Probability mass.* Say we have a probability mass function $p(x)$ that puts probability on just three outcomes: 1, 3, and 5. We know that $p(1) = 0.4$, and we know that $p(3) = p(5)$. What must $p(3)$ and $p(5)$ be? Why?

2. *Probability density.* Say we have a uniform distribution on the range from 3.0 to 3.1. This distribution, like all uniform distributions, has the same probability density $p(x)$ at every point $x$ within its range $[3.0, 3.1]$. What is the probability density $p(x)$ at each of these points? Why do you know this? Is it a problem that this probability density is greater than 1? Why or why not?

3. *Bernoulli trial distribution.* We often say that the Bernoulli trial has a single parameter, the probability of a 'success', often denoted $\pi$. In terms of $\pi$, what is the probability of a failure? Why?

4. *Mean and variance.* Say we have a multinomial trial distribution $p(x)$ over three outcomes 1, 2, and 4, where $p(1) = 0.3$, $p(2) = 0.4$, and $p(4) = 0.3$. What is the expectation or mean of this distribution? What is the variance? What is the standard deviation? (show how you got these results)

Data summarization and plotting in R
------------------------------------

For this part of the homework, you'll be making use of a data file called `schilling_ling300.txt`, also available from the course website. This file was constructed from a freely available dataset of eye movements in reading called the Schilling corpus (Schilling, Rayner, & Chumbley, 1998). This corpus was created when participants read a number of short sentences while their eyes were being tracked. The file I've provided you with describes, for a number of words and for each of 9 subjects, three binary eye movement measures that relate to ongoing language processing:

* whether the subject _skipped_ that word, which means not directly fixating the word before fixating words past it
* whether the subject made _multiple fixations_ on the word prior to moving the eyes to words past it
* whether the subject made a _regression_ on the word, which means moving the eyes backwards to previous words, prior to moving the eyes past it

In general, words that take less time to process are associated with more _skipping_, and words that take longer to process are associated with more instances of _multiple fixations_ and more _regressions_. For the purposes of this homework, we'll be looking at the relationships between these three eye movement measures and one measure of how long it takes to process a word: its length in characters. On average, words that are longer take longer to process, so the expectation is that as length increases, words will be associated with less skipping, more instances of multiple fixations, and more regressions.

5. *Getting to know the dataset without R.* For text-encoded datasets such as this one (and the one we used in class), it's usually a good idea to look at the dataset in a text editor of some sort before loading it into R. This can help you decide which commands and options to use to load the dataset. If you're comfortable on a *nix-style terminal, using the `head` command is a great way to look at a dataset. If not, just open this file in your favorite text editor, or just open this file in RStudio with File -> Open File... to look at it. (Make sure not to accidentally save any changes to the file.)
    + You'll notice that the file has 6 columns, separated by a tab. Each column has a name, given in the first row (*header row*):
        * _subj_. subject number, uniquely identifying participants
        * _word_. word number, in the form [sentence number]_[word number in sentence]
        * _wlen_. length of word, in characters
        * _skip_. a 1 if the word was skipped by this subject and 0 otherwise
        * _mfix_. a 1 if the word was fixated multiple times by this subject and 0 otherwise
        * _fp.reg_. a 1 if a regression was launched from this word back to a previous word by this subject, and a 0 otherwise. If a word was skipped, the value for fp.reg is NA, since if the reader did not fixate the word, they had no opportunity to launch a regression from it
    + Looking just at the first 10 lines of this file (so the first 9 lines of data, since row 1 is the header), what range of word lengths does it seem that this dataset is investigating? Also, looking at these rows of data, which outcome seems to be least likely: skipping a word, fixating a word multiple times, or launching a regression from a word?

```{r}
summary(cars)
```

2. You can also embed plots, for example:

```{r, echo=FALSE}
plot(cars)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
